[{"id":"f4835500-4c4a-11ea-9c79-f31d60741e3b","name":"DownloadToBronzeHdfs","steps":[{"id":"DownloadToHdfs","displayName":"Step Group","description":"Allows pipelines to be executed as a single step within a parent pipeline.","type":"step-group","params":[{"type":"text","name":"pipelineId","required":false,"value":"46f5e310-4c47-11ea-a0a7-a749c3ebbd62","description":""},{"type":"text","name":"pipeline","required":false,"value":"&46f5e310-4c47-11ea-a0a7-a749c3ebbd62","description":""},{"type":"object","name":"pipelineMappings","required":false,"value":{"fileId":"!fileId","output_buffer_size":"!outputBufferSize || 65536","input_buffer_size":"!inputBufferSize || 65536","sftp_port":"!sftpPort || 22","sftp_input_path":"!sftpInputPath","sftp_username":"!sftpUsername","landing_path":"!landingPath","sftp_password":"!sftpPassword","read_buffer_size":"!readBufferSize || 32768","sftp_host":"!sftpHost"},"description":""}],"nextStepId":"LandingFileToDataFrame","stepId":"f09b3b9c-82ac-56de-8dc8-f57c063dd4aa","retryLimit":-1},{"id":"LandingFileToDataFrame","displayName":"Load DataFrame from HDFS path","description":"This step will read a dataFrame from the given HDFS path","type":"Pipeline","params":[{"type":"text","name":"path","required":false,"value":"!{landingPath}/!{fileId}","description":""},{"type":"object","name":"options","required":false,"value":"!inputReaderOptions","className":"com.acxiom.pipeline.steps.DataFrameReaderOptions","description":""}],"engineMeta":{"spark":"HDFSSteps.readFromPath","pkg":"com.acxiom.pipeline.steps"},"nextStepId":"StandardizeColumnNames","stepId":"87db259d-606e-46eb-b723-82923349640f","retryLimit":-1},{"id":"StandardizeColumnNames","displayName":"Standardize Column Names on a DataFrame","description":"This step will standardize columns names on existing dataframe","type":"Pipeline","params":[{"type":"text","name":"dataFrame","required":false,"value":"@LandingFileToDataFrame","description":""}],"engineMeta":{"spark":"TransformationSteps.standardizeColumnNames","pkg":"com.acxiom.pipeline.steps"},"nextStepId":"AddRecordId","stepId":"a981080d-714c-4d36-8b09-d95842ec5655","retryLimit":-1},{"id":"AddRecordId","displayName":"Adds a Unique Identifier to a DataFrame","description":"This step will add a new unique identifier to an existing data frame","type":"Pipeline","params":[{"type":"text","name":"idColumnName","required":false,"value":"metalus_record_id","description":""},{"type":"text","name":"dataFrame","required":false,"value":"@StandardizeColumnNames","description":""}],"engineMeta":{"spark":"DataSteps.addUniqueIdToDataFrame","pkg":"com.acxiom.pipeline.steps"},"nextStepId":"AddFileId","stepId":"9f7d84b0-ebab-57da-8b39-be4c47028242","retryLimit":-1},{"id":"AddFileId","displayName":"Add a Column with a Static Value to All Rows in a DataFrame","description":"This step will add a column with a static value to all rows in the provided data frame","type":"Pipeline","params":[{"type":"text","name":"dataFrame","required":false,"value":"@AddRecordId","description":""},{"type":"text","name":"columnName","required":false,"value":"metalus_file_id","description":""},{"type":"text","name":"columnValue","required":false,"value":"!fileId","description":""}],"engineMeta":{"spark":"DataSteps.addStaticColumnToDataFrame","pkg":"com.acxiom.pipeline.steps"},"nextStepId":"WriteToParquetHdfs","stepId":"80583aa9-41b7-4906-8357-cc2d3670d970","retryLimit":-1},{"id":"WriteToParquetHdfs","displayName":"Write DataFrame to HDFS","description":"This step will write a dataFrame in a given format to HDFS","type":"Pipeline","params":[{"type":"text","name":"dataFrame","required":false,"value":"@AddFileId","description":""},{"type":"text","name":"path","required":false,"value":"!{bronzeZonePath}/!{fileId}","description":""},{"type":"object","name":"options","required":false,"value":{"format":"parquet","saveMode":"Overwrite","options":{},"schema":{"attributes":[]}},"className":"com.acxiom.pipeline.steps.DataFrameWriterOptions","description":""}],"engineMeta":{"spark":"HDFSSteps.writeToPath","pkg":"com.acxiom.pipeline.steps"},"stepId":"0a296858-e8b7-43dd-9f55-88d00a7cd8fa","retryLimit":-1}],"category":"pipeline","tags":["metalus-common_2.11-spark_2.4-1.9.0.jar"]},{"id":"streaming-monitor","name":"Streaming Monitor","steps":[{"id":"Monitor","displayName":"Streaming Monitor","description":"Given a StreamingQuery, this step will invoke the monitor thread and wait while records are processed. The monitor class will be used to stop the query and determine if further processing should occur.","type":"branch","params":[{"type":"text","name":"query","required":false,"value":"!STREAMING_QUERY","className":"org.apache.spark.sql.streaming.StreamingQuery","parameterType":"org.apache.spark.sql.streaming.StreamingQuery","description":"Pulls the Streaming Query from the global STREAMING_QUERY"},{"type":"text","name":"streamingMonitorClassName","required":false,"value":"!STREAMING_MONITOR_CLASS_NAME || com.acxiom.pipeline.streaming.BaseStreamingQueryMonitor","description":"Maps the value from the STREAMING_MONITOR_CLASS_NAME global. The default class used is com.acxiom.pipeline.streaming.BaseStreamingQueryMonitor which will continue running."},{"type":"result","name":"continue","required":false,"description":""},{"type":"result","name":"stop","required":false,"value":"LOG_STOP","description":""}],"engineMeta":{"spark":"FlowUtilsSteps.monitorStreamingQuery","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"com.acxiom.pipeline.PipelineStepResponse"}},"stepId":"64c983e2-5eac-4fb6-87b2-024b69aa0ded","retryLimit":-1},{"id":"LOG_STOP","displayName":"Log Message","description":"Log a simple message","type":"Pipeline","params":[{"type":"text","name":"message","required":true,"value":"End of streaming query","description":"The message to log"},{"type":"text","name":"level","required":true,"value":"INFO","description":"Log level at which to log. Should be a valid log4j level"}],"engineMeta":{"spark":"LoggingSteps.logMessage","pkg":"com.acxiom.pipeline.steps"},"stepId":"931ad4e5-4501-4716-853a-30fbf8fb6090","retryLimit":-1}],"category":"step-group","tags":["metalus-common_2.11-spark_2.4-1.9.0.jar"],"description":"Provides a simple pipeline to monitor streaming queries. This pipeline is designed to be chained to other pipelines/executions and provide a log when the streaming query stops. There is no behavior to continue one the query stops."},{"id":"dcff1d10-c2c3-11eb-928b-3dca5c59af1b","name":"LoadToParquet","steps":[{"id":"LoadDataFrame","displayName":"Step Group","description":"Allows pipelines to be executed as a single step within a parent pipeline.","type":"step-group","params":[{"type":"text","name":"pipelineId","required":false,"value":"!loadDataFramePipelineId","description":"The id of the pipeline to execute. Either this parameter or the pipeline parameter must be set."},{"type":"text","name":"pipeline","required":false,"description":"The pipeline to execute. Either this parameter or the pipelineId parameter must be set. This may be a mapped value or a pipeline object."},{"type":"boolean","name":"useParentGlobals","required":false,"value":true,"description":"Indicates whether the calling pipeline globals should be merged with the pipelineMappings."},{"type":"object","name":"pipelineMappings","required":false,"value":{},"description":"The values to use as the globals for the pipeline. Values may be mapped from the outer pipeline context."}],"nextStepId":"ExecuteColumnCleanup","stepId":"f09b3b9c-82ac-56de-8dc8-f57c063dd4aa","retryLimit":-1},{"id":"ExecuteColumnCleanup","displayName":"String Equals","description":"Return whether string1 equals string2","type":"branch","params":[{"type":"text","name":"string","required":true,"value":"!executeColumnCleanup || true","description":"The string to compare"},{"type":"text","name":"anotherString","required":true,"value":"true","description":"The other string to compare"},{"type":"boolean","name":"caseInsensitive","required":false,"value":true,"description":"Boolean flag to indicate case sensitive compare"},{"type":"result","name":"true","required":false,"value":"StandardizeColumnNames","description":""},{"type":"result","name":"false","required":false,"value":"AddRecordIdDecision","description":""}],"engineMeta":{"spark":"StringSteps.stringEquals","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"Boolean"}},"stepId":"3fabf9ec-5383-4eb3-81af-6092ab7c370d","retryLimit":-1},{"id":"StandardizeColumnNames","displayName":"Standardize Column Names on a DataFrame","description":"This step will standardize columns names on existing dataframe","type":"Pipeline","params":[{"type":"text","name":"dataFrame","required":false,"value":"@LoadDataFrame","description":""}],"engineMeta":{"spark":"TransformationSteps.standardizeColumnNames","pkg":"com.acxiom.pipeline.steps"},"nextStepId":"AddRecordIdDecision","stepId":"a981080d-714c-4d36-8b09-d95842ec5655","retryLimit":-1},{"id":"AddRecordIdDecision","displayName":"String Equals","description":"Return whether string1 equals string2","type":"branch","params":[{"type":"text","name":"string","required":true,"value":"!addRecordId || true","description":"The string to compare"},{"type":"text","name":"anotherString","required":true,"value":"true","description":"The other string to compare"},{"type":"boolean","name":"caseInsensitive","required":false,"value":true,"description":"Boolean flag to indicate case sensitive compare"},{"type":"result","name":"true","required":false,"value":"AddRecordId","description":""},{"type":"result","name":"false","required":false,"value":"AddFileIdDecision","description":""}],"engineMeta":{"spark":"StringSteps.stringEquals","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"Boolean"}},"stepId":"3fabf9ec-5383-4eb3-81af-6092ab7c370d","retryLimit":-1},{"id":"AddRecordId","displayName":"Adds a Unique Identifier to a DataFrame","description":"This step will add a new unique identifier to an existing data frame","type":"Pipeline","params":[{"type":"text","name":"idColumnName","required":false,"value":"metalus_record_id","description":""},{"type":"text","name":"dataFrame","required":false,"value":"@StandardizeColumnNames || @LoadDataFrame","description":""}],"engineMeta":{"spark":"DataSteps.addUniqueIdToDataFrame","pkg":"com.acxiom.pipeline.steps"},"nextStepId":"AddFileIdDecision","stepId":"9f7d84b0-ebab-57da-8b39-be4c47028242","retryLimit":-1},{"id":"AddFileIdDecision","displayName":"String Equals","description":"Return whether string1 equals string2","type":"branch","params":[{"type":"text","name":"string","required":true,"value":"!addFileId || true","description":"The string to compare"},{"type":"text","name":"anotherString","required":true,"value":"true","description":"The other string to compare"},{"type":"boolean","name":"caseInsensitive","required":false,"value":true,"description":"Boolean flag to indicate case sensitive compare"},{"type":"result","name":"true","required":false,"value":"AddFileId","description":""},{"type":"result","name":"false","required":false,"value":"WriteDataFrame","description":""}],"engineMeta":{"spark":"StringSteps.stringEquals","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"Boolean"}},"stepId":"3fabf9ec-5383-4eb3-81af-6092ab7c370d","retryLimit":-1},{"id":"AddFileId","displayName":"Add a Column with a Static Value to All Rows in a DataFrame","description":"This step will add a column with a static value to all rows in the provided data frame","type":"Pipeline","params":[{"type":"text","name":"dataFrame","required":false,"value":"@AddRecordId || @StandardizeColumnNames || @LoadDataFrame","description":""},{"type":"text","name":"columnName","required":false,"value":"metalus_file_id","description":""},{"type":"text","name":"columnValue","required":false,"value":"!fileId","description":""}],"engineMeta":{"spark":"DataSteps.addStaticColumnToDataFrame","pkg":"com.acxiom.pipeline.steps"},"nextStepId":"WriteDataFrame","stepId":"80583aa9-41b7-4906-8357-cc2d3670d970","retryLimit":-1},{"id":"WriteDataFrame","displayName":"Step Group","description":"Allows pipelines to be executed as a single step within a parent pipeline.","type":"step-group","params":[{"type":"text","name":"pipelineId","required":false,"value":"!writeDataFramePipelineId","description":"The id of the pipeline to execute. Either this parameter or the pipeline parameter must be set."},{"type":"text","name":"pipeline","required":false,"description":"The pipeline to execute. Either this parameter or the pipelineId parameter must be set. This may be a mapped value or a pipeline object."},{"type":"boolean","name":"useParentGlobals","required":false,"value":true,"description":"Indicates whether the calling pipeline globals should be merged with the pipelineMappings."},{"type":"object","name":"pipelineMappings","required":false,"value":{"inputDataFrame":"@AddFileId || @AddRecordId || @StandardizeColumnNames || @LoadDataFrame"},"description":"The values to use as the globals for the pipeline. Values may be mapped from the outer pipeline context."}],"stepId":"f09b3b9c-82ac-56de-8dc8-f57c063dd4aa","retryLimit":-1}],"category":"pipeline","tags":["metalus-common_2.11-spark_2.4-1.9.0.jar"]},{"id":"189328f0-c2c7-11eb-928b-3dca5c59af1b","name":"WriteDataFrameToHDFS","steps":[{"id":"WriteToParquetHdfs","displayName":"Write DataFrame to HDFS","description":"This step will write a dataFrame in a given format to HDFS","type":"Pipeline","params":[{"type":"text","name":"dataFrame","required":true,"value":"!inputDataFrame","description":"The DataFrame to write"},{"type":"text","name":"path","required":true,"value":"!{bronzeZonePath}/!{fileId}","description":"The GCS path to write data"},{"type":"object","name":"options","required":false,"value":{"format":"parquet","bucketingOptions":{},"options":{"escapeQuotes":false},"schema":{"attributes":[]},"saveMode":"Overwrite"},"className":"com.acxiom.pipeline.steps.DataFrameWriterOptions","description":"The optional DataFrame Options"}],"engineMeta":{"spark":"HDFSSteps.writeToPath","pkg":"com.acxiom.pipeline.steps"},"stepId":"0a296858-e8b7-43dd-9f55-88d00a7cd8fa","retryLimit":-1}],"category":"step-group","tags":["metalus-common_2.11-spark_2.4-1.9.0.jar"]},{"id":"46f5e310-4c47-11ea-a0a7-a749c3ebbd62","name":"SG_SftpToHdfs","steps":[{"id":"CreateSFTPFileManager","displayName":"Create SFTP FileManager","description":"Simple function to generate the SFTPFileManager for the remote SFTP file system","type":"Pipeline","params":[{"type":"text","name":"hostName","required":false,"value":"!sftp_host","description":""},{"type":"text","name":"username","required":false,"value":"!sftp_username","description":""},{"type":"text","name":"password","required":false,"value":"!sftp_password","description":""},{"type":"integer","name":"port","required":false,"value":"!sftp_port || 22","description":""},{"type":"text","name":"strictHostChecking","required":false,"value":false,"description":""}],"engineMeta":{"spark":"SFTPSteps.createFileManager","pkg":"com.acxiom.pipeline.steps"},"nextStepId":"CreateHDFSFileManager","stepId":"9d467cb0-8b3d-40a0-9ccd-9cf8c5b6cb38","retryLimit":-1},{"id":"CreateHDFSFileManager","displayName":"Create HDFS FileManager","description":"Simple function to generate the HDFSFileManager for the local HDFS file system","type":"Pipeline","params":[],"engineMeta":{"spark":"HDFSSteps.createFileManager","pkg":"com.acxiom.pipeline.steps"},"nextStepId":"DownloadFile","stepId":"e4dad367-a506-5afd-86c0-82c2cf5cd15c","retryLimit":-1},{"id":"DownloadFile","displayName":"Buffered file copy","description":"Copy the contents of the source path to the destination path using full buffer sizes. This function will call connect on both FileManagers.","type":"Pipeline","params":[{"type":"text","name":"srcFS","required":false,"value":"@CreateSFTPFileManager","description":""},{"type":"text","name":"srcPath","required":false,"value":"!sftp_input_path","description":""},{"type":"text","name":"destFS","required":false,"value":"@CreateHDFSFileManager","description":""},{"type":"text","name":"destPath","required":false,"value":"!{landing_path}/!{fileId}","description":""},{"type":"text","name":"inputBufferSize","required":false,"value":"!input_buffer_size || 65536","description":""},{"type":"text","name":"outputBufferSize","required":false,"value":"!output_buffer_size || 65536","description":""},{"type":"text","name":"copyBufferSize","required":false,"value":"!read_buffer_size || 32768","description":""}],"engineMeta":{"spark":"FileManagerSteps.copy","pkg":"com.acxiom.pipeline.steps"},"nextStepId":"DisconnectSFTPFileManager","stepId":"f5a24db0-e91b-5c88-8e67-ab5cff09c883","retryLimit":-1},{"id":"DisconnectSFTPFileManager","displayName":"Disconnect a FileManager","description":"Disconnects a FileManager from the underlying file system","type":"Pipeline","params":[{"type":"text","name":"fileManager","required":false,"value":"@CreateSFTPFileManager","description":""}],"engineMeta":{"spark":"FileManagerSteps.disconnectFileManager","pkg":"com.acxiom.pipeline.steps"},"stepId":"3d1e8519-690c-55f0-bd05-1e7b97fb6633","retryLimit":-1}],"category":"step-group","tags":["metalus-common_2.11-spark_2.4-1.9.0.jar"]},{"id":"a9f62840-2827-11ec-9c0c-cbf3549779e5","name":"LoadToBronze","steps":[{"id":"START_LOG","displayName":"Log Message","description":"Logs the start of the pipeline","type":"Pipeline","params":[{"type":"text","name":"message","required":true,"value":"Starting Load To Bronze","parameterType":"String","description":"Indicates that the logging pipeline has started"},{"type":"text","name":"level","required":true,"value":"INFO","parameterType":"String","description":"Setting the log to info."}],"engineMeta":{"spark":"LoggingSteps.logMessage","pkg":"com.acxiom.pipeline.steps"},"nextStepId":"Load","stepId":"931ad4e5-4501-4716-853a-30fbf8fb6090","retryLimit":-1},{"id":"Load","displayName":"Load","description":"Loads the data using the specified connector information","type":"Pipeline","params":[{"type":"text","name":"connector","required":true,"value":"!sourceBronzeConnector","parameterType":"com.acxiom.pipeline.connectors.DataConnector","description":"Maps the connector using the sourceBronzeConnector global"},{"type":"text","name":"source","required":false,"value":"!sourceBronzePath","parameterType":"String","description":"Maps the path using the sourceBronzePath global"},{"type":"object","name":"readOptions","required":false,"value":"!sourceBronzeReadOptions","className":"com.acxiom.pipeline.steps.DataFrameReaderOptions","parameterType":"com.acxiom.pipeline.steps.DataFrameReaderOptions","description":"Maps the read options from the sourceBronzeReadOptions global"}],"engineMeta":{"spark":"DataConnectorSteps.loadDataFrame","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"org.apache.spark.sql.DataFrame"}},"nextStepId":"ExecuteColumnCleanup","stepId":"836aab38-1140-4606-ab73-5b6744f0e7e7","retryLimit":-1},{"id":"ExecuteColumnCleanup","displayName":"String Equals","description":"Determines whether column names should be standardized","type":"branch","params":[{"type":"text","name":"string","required":true,"value":"!executeColumnCleanup || true","description":"Uses the value from the executeColumnCleanup global. A value of true is required to run the cleanup. Default is true,"},{"type":"text","name":"anotherString","required":true,"value":"true","description":"This value (true) is compared against the mapped value."},{"type":"boolean","name":"caseInsensitive","required":false,"value":true,"description":"Set to ignore the case of the mapped value."},{"type":"result","name":"true","required":false,"value":"StandardizeColumnNames","description":""},{"type":"result","name":"false","required":false,"value":"AddRecordIdDecision","description":""}],"engineMeta":{"spark":"StringSteps.stringEquals","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"Boolean"}},"stepId":"3fabf9ec-5383-4eb3-81af-6092ab7c370d","retryLimit":-1},{"id":"StandardizeColumnNames","displayName":"Standardize Column Names on a DataFrame","description":"This step will standardize columns names on existing dataframe","type":"Pipeline","params":[{"type":"text","name":"dataFrame","required":false,"value":"@Load","description":"The data from the Load step."}],"engineMeta":{"spark":"TransformationSteps.standardizeColumnNames","pkg":"com.acxiom.pipeline.steps"},"nextStepId":"AddRecordIdDecision","stepId":"a981080d-714c-4d36-8b09-d95842ec5655","retryLimit":-1},{"id":"AddRecordIdDecision","displayName":"String Equals","description":"Determines whether a record id should be added to each row","type":"branch","params":[{"type":"text","name":"string","required":true,"value":"!addRecordId || $useRecordId || true","description":"Maps the value from the addRecordId global or useRecordId runtime parameter to determine whether to add a record id to the data"},{"type":"text","name":"anotherString","required":true,"value":"true","description":"This value (true) is compared against the mapped value."},{"type":"boolean","name":"caseInsensitive","required":false,"value":true,"description":"Set to ignore the case of the mapped value."},{"type":"result","name":"true","required":false,"value":"AddRecordId","description":""},{"type":"result","name":"false","required":false,"value":"AddFileIdDecision","description":""}],"engineMeta":{"spark":"StringSteps.stringEquals","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"Boolean"}},"stepId":"3fabf9ec-5383-4eb3-81af-6092ab7c370d","retryLimit":-1},{"id":"AddRecordId","displayName":"Adds a Unique Identifier to a DataFrame","description":"This step will add a new unique identifier to an existing data frame","type":"Pipeline","params":[{"type":"text","name":"idColumnName","required":false,"value":"metalus_record_id","description":"The name of the column that will contain the new column. The column will be named metalus_record_id."},{"type":"text","name":"dataFrame","required":false,"value":"@StandardizeColumnNames || @LoadDataFrame","description":"The current data set"}],"engineMeta":{"spark":"DataSteps.addUniqueIdToDataFrame","pkg":"com.acxiom.pipeline.steps"},"nextStepId":"AddFileIdDecision","stepId":"9f7d84b0-ebab-57da-8b39-be4c47028242","retryLimit":-1},{"id":"AddFileIdDecision","displayName":"String Equals","description":"Determines whether the file id should be added to each record","type":"branch","params":[{"type":"text","name":"string","required":true,"value":"!addFileId || true","description":"Maps the value from the addFileId global. Default is true."},{"type":"text","name":"anotherString","required":true,"value":"true","description":"This value (true) is compared against the mapped value."},{"type":"boolean","name":"caseInsensitive","required":false,"value":true,"description":"Set to ignore the case of the mapped value."},{"type":"result","name":"true","required":false,"value":"AddFileId","description":""},{"type":"result","name":"false","required":false,"value":"AddStaticPartitionColumn","description":""}],"engineMeta":{"spark":"StringSteps.stringEquals","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"Boolean"}},"stepId":"3fabf9ec-5383-4eb3-81af-6092ab7c370d","retryLimit":-1},{"id":"AddFileId","displayName":"Add a Column with a Static Value to All Rows in a DataFrame","description":"This step will add a column with a static value to all rows in the provided data frame","type":"Pipeline","params":[{"type":"text","name":"dataFrame","required":false,"value":"@AddRecordId || @StandardizeColumnNames || @LoadDataFrame","description":"The current data set"},{"type":"text","name":"columnName","required":false,"value":"metalus_file_id","description":"Sets the column name to metalus_file_id."},{"type":"text","name":"columnValue","required":false,"value":"!fileId","description":"Maps the value from the fileId global"}],"engineMeta":{"spark":"DataSteps.addStaticColumnToDataFrame","pkg":"com.acxiom.pipeline.steps"},"nextStepId":"AddStaticPartitionColumn","stepId":"80583aa9-41b7-4906-8357-cc2d3670d970","retryLimit":-1},{"id":"AddStaticPartitionColumn","displayName":"String Equals","description":"Determines whether a column should be added to each record that can be used for partitioning the data","type":"branch","params":[{"type":"text","name":"string","required":true,"value":"!AddPartitionColumn","parameterType":"String","description":"Maps the value from the AddPartitionColumn global"},{"type":"text","name":"anotherString","required":true,"value":"true","parameterType":"String","description":"This value (true) is compared against the mapped value."},{"type":"boolean","name":"caseInsensitive","required":false,"value":true,"parameterType":"Boolean","description":"Set to ignore the case of the mapped value."},{"type":"result","name":"true","required":false,"value":"AddPartitionColumn","description":""},{"type":"result","name":"false","required":false,"value":"Write","description":""}],"engineMeta":{"spark":"StringSteps.stringEquals","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"Boolean"}},"stepId":"3fabf9ec-5383-4eb3-81af-6092ab7c370d","retryLimit":-1},{"id":"AddPartitionColumn","displayName":"Add a Column with a Static Value to All Rows in a DataFrame (metalus-common)","description":"This step will add a column with a static value to all rows in the provided data frame","type":"Pipeline","params":[{"type":"text","name":"dataFrame","required":true,"value":"@AddFileId || @AddRecordId || @StandardizeColumnNames || @Load","parameterType":"org.apache.spark.sql.Dataset[_]","description":"The current data set"},{"type":"text","name":"columnName","required":true,"value":"!partitionColumnNameBronze || partition_column","parameterType":"String","description":"Maps the value of the partitionColumnNameBronze global or defaults to partition_column."},{"type":"text","name":"columnValue","required":true,"value":"!PARTITION_VALUE","parameterType":"Any","description":"Maps the value of the PARTITION_VALUE global."},{"type":"boolean","name":"standardizeColumnName","required":false,"defaultValue":"true","value":false,"parameterType":"Boolean","description":"Set to false so the mapped value is used as is."}],"engineMeta":{"spark":"DataSteps.addStaticColumnToDataFrame","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"org.apache.spark.sql.DataFrame"}},"nextStepId":"Write","stepId":"80583aa9-41b7-4906-8357-cc2d3670d970","retryLimit":-1},{"id":"Write","displayName":"Write","description":"This step will write a DataFrame using the given DataConnector","type":"Pipeline","params":[{"type":"text","name":"dataFrame","required":true,"value":"@AddPartitionColumn || @AddFileId || @AddRecordId || @StandardizeColumnNames || @Load","parameterType":"org.apache.spark.sql.DataFrame","description":"The current data set."},{"type":"text","name":"connector","required":true,"value":"!destinationBronzeConnector","parameterType":"com.acxiom.pipeline.connectors.DataConnector","description":"Maps the value from the destinationBronzeConnector global."},{"type":"text","name":"destination","required":false,"value":"!destinationBronzePath","parameterType":"String","description":"Maps the value from the destinationBronzePath global."},{"type":"object","name":"writeOptions","required":false,"value":"!destinationBronzeWriteOptions","className":"com.acxiom.pipeline.steps.DataFrameWriterOptions","parameterType":"com.acxiom.pipeline.steps.DataFrameWriterOptions","description":"Maps the value from the destinationBronzeWriteOptions global."}],"engineMeta":{"spark":"DataConnectorSteps.writeDataFrame","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"org.apache.spark.sql.streaming.StreamingQuery"}},"nextStepId":"StreamingMonitor","stepId":"5608eba7-e9ff-48e6-af77-b5e810b99d89","retryLimit":-1},{"id":"StreamingMonitor","displayName":"Streaming Monitor","description":"Given a StreamingQuery, this step will invoke the monitor thread and wait while records are processed. The monitor class will be used to stop the query and determine if further processing should occur.","type":"branch","params":[{"type":"text","name":"query","required":false,"value":"@Write","parameterType":"org.apache.spark.sql.streaming.StreamingQuery","description":"The streaming query from the Write step if a streaming connector was used."},{"type":"text","name":"streamingMonitorClassName","required":false,"value":"!STREAMING_MONITOR_CLASS_NAME || com.acxiom.pipeline.streaming.BaseStreamingQueryMonitor","parameterType":"String","description":"Maps the value from the STREAMING_MONITOR_CLASS_NAME global. The default class used is com.acxiom.pipeline.streaming.BaseStreamingQueryMonitor which will continue running."},{"type":"result","name":"continue","required":false,"value":"Load","description":""},{"type":"result","name":"stop","required":false,"value":"END_LOG","description":""}],"engineMeta":{"spark":"FlowUtilsSteps.monitorStreamingQuery","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"com.acxiom.pipeline.PipelineStepResponse"}},"stepId":"64c983e2-5eac-4fb6-87b2-024b69aa0ded","retryLimit":-1},{"id":"END_LOG","displayName":"Log Message","description":"Log a simple message","type":"Pipeline","params":[{"type":"text","name":"message","required":true,"value":"Finished Load To Bronze Pipeline. Streaming was not used.","parameterType":"String","description":"Adds a log message that the pipeline has completed."},{"type":"text","name":"level","required":true,"value":"INFO","parameterType":"String","description":"Setting the log to info."}],"engineMeta":{"spark":"LoggingSteps.logMessage","pkg":"com.acxiom.pipeline.steps"},"executeIfEmpty":"@Write","stepId":"931ad4e5-4501-4716-853a-30fbf8fb6090","retryLimit":-1}],"category":"pipeline","tags":["metalus-common_2.11-spark_2.4-1.9.0.jar"],"description":"Loads data from thee provided source location, performs optional tasks such as standardizing column names, adding a unique record id, adding the file id and adding a partition column. This pipeline also supports streaming connectors and may be used as the final pipeline in a streaming query."},{"id":"e9ce4710-beda-11eb-977b-1f7c49e5a75d","name":"DownloadSFTPToHDFSWithDataFrame","steps":[{"id":"CreateSFTPFileManager","displayName":"Create SFTP FileManager","description":"Simple function to generate the SFTPFileManager for the remote SFTP file system","type":"Pipeline","params":[{"type":"text","name":"hostName","required":false,"value":"!sftp_host","description":""},{"type":"text","name":"username","required":false,"value":"!sftp_username","description":""},{"type":"text","name":"password","required":false,"value":"!sftp_password","description":""},{"type":"integer","name":"port","required":false,"value":"!sftp_port || 22","description":""},{"type":"text","name":"strictHostChecking","required":false,"value":false,"description":""}],"engineMeta":{"spark":"SFTPSteps.createFileManager","pkg":"com.acxiom.pipeline.steps"},"nextStepId":"CreateHDFSFileManager","stepId":"9d467cb0-8b3d-40a0-9ccd-9cf8c5b6cb38","retryLimit":-1},{"id":"CreateHDFSFileManager","displayName":"Create HDFS FileManager","description":"Simple function to generate the HDFSFileManager for the local HDFS file system","type":"Pipeline","params":[],"engineMeta":{"spark":"HDFSSteps.createFileManager","pkg":"com.acxiom.pipeline.steps"},"nextStepId":"DownloadFile","stepId":"e4dad367-a506-5afd-86c0-82c2cf5cd15c","retryLimit":-1},{"id":"DownloadFile","displayName":"Buffered file copy","description":"Copy the contents of the source path to the destination path using full buffer sizes. This function will call connect on both FileManagers.","type":"Pipeline","params":[{"type":"text","name":"srcFS","required":false,"value":"@CreateSFTPFileManager","description":""},{"type":"text","name":"srcPath","required":false,"value":"!sftp_input_path","description":""},{"type":"text","name":"destFS","required":false,"value":"@CreateHDFSFileManager","description":""},{"type":"text","name":"destPath","required":false,"value":"!{landing_path}/!{fileId}","description":""},{"type":"text","name":"inputBufferSize","required":false,"value":"!input_buffer_size || 65536","description":""},{"type":"text","name":"outputBufferSize","required":false,"value":"!output_buffer_size || 65536","description":""},{"type":"text","name":"copyBufferSize","required":false,"value":"!read_buffer_size || 32768","description":""}],"engineMeta":{"spark":"FileManagerSteps.copy","pkg":"com.acxiom.pipeline.steps"},"nextStepId":"DisconnectSFTPFileManager","stepId":"f5a24db0-e91b-5c88-8e67-ab5cff09c883","retryLimit":-1},{"id":"DisconnectSFTPFileManager","displayName":"Disconnect a FileManager","description":"Disconnects a FileManager from the underlying file system","type":"Pipeline","params":[{"type":"text","name":"fileManager","required":false,"value":"@CreateSFTPFileManager","description":""}],"engineMeta":{"spark":"FileManagerSteps.disconnectFileManager","pkg":"com.acxiom.pipeline.steps"},"nextStepId":"LandingFileToDataFrame","stepId":"3d1e8519-690c-55f0-bd05-1e7b97fb6633","retryLimit":-1},{"id":"LandingFileToDataFrame","displayName":"Load DataFrame from HDFS path","description":"This step will read a dataFrame from the given HDFS path","type":"Pipeline","params":[{"type":"text","name":"path","required":true,"value":"!{landingPath}/!{fileId}","description":"The HDFS path to load data into the DataFrame"},{"type":"object","name":"options","required":false,"value":"!readOptions","className":"com.acxiom.pipeline.steps.DataFrameReaderOptions","description":"The options to use when loading the DataFrameReader"}],"engineMeta":{"spark":"HDFSSteps.readFromPath","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"org.apache.spark.sql.DataFrame"}},"stepId":"87db259d-606e-46eb-b723-82923349640f","retryLimit":-1}],"category":"step-group","tags":["metalus-common_2.11-spark_2.4-1.9.0.jar"],"stepGroupResult":"@LandingFileToDataFrame"},{"id":"43bc9450-2689-11ec-9c0c-cbf3549779e5","name":"CopyFile","steps":[{"id":"GETSOURCE","displayName":"Create a FileManager","description":"Creates a FileManager that represents the source.","type":"Pipeline","params":[{"type":"text","name":"fileConnector","required":true,"value":"!sourceConnector","parameterType":"com.acxiom.pipeline.connectors.FileConnector","description":"Maps the value from the sourceConnector global."}],"engineMeta":{"spark":"FileManagerSteps.getFileManager","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"com.acxiom.pipeline.fs.FileManager"}},"nextStepId":"GETDESTINATION","stepId":"259a880a-3e12-4843-9f02-2cfc2a05f576","retryLimit":-1},{"id":"GETDESTINATION","displayName":"Create a FileManager","description":"Creates a FileManager that represents the destination.","type":"Pipeline","params":[{"type":"text","name":"fileConnector","required":true,"value":"!destinationConnector","parameterType":"com.acxiom.pipeline.connectors.FileConnector","description":"Maps the value from the destinationConnector global."}],"engineMeta":{"spark":"FileManagerSteps.getFileManager","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"com.acxiom.pipeline.fs.FileManager"}},"nextStepId":"COPY","stepId":"259a880a-3e12-4843-9f02-2cfc2a05f576","retryLimit":-1},{"id":"COPY","displayName":"Copy (auto buffering)","description":"Copies the data from the source to the destination.","type":"Pipeline","params":[{"type":"text","name":"srcFS","required":true,"value":"@GETSOURCE","parameterType":"com.acxiom.pipeline.fs.FileManager","description":"The source FileManager"},{"type":"text","name":"srcPath","required":true,"value":"!sourceCopyPath","parameterType":"String","description":"Maps the value from the sourceCopyPath global."},{"type":"text","name":"destFS","required":true,"value":"@GETDESTINATION","parameterType":"com.acxiom.pipeline.fs.FileManager","description":"The destination FileManager"},{"type":"text","name":"destPath","required":true,"value":"!destinationCopyPath","parameterType":"String","description":"Maps the value from the destinationCopyPath global."}],"engineMeta":{"spark":"FileManagerSteps.copy","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"com.acxiom.pipeline.steps.CopyResults"}},"nextStepId":"VERIFY","stepId":"0342654c-2722-56fe-ba22-e342169545af","nextStepOnError":"DELETEDESTINATION","retryLimit":-1},{"id":"VERIFY","displayName":"Compare File Sizes","description":"Verifies that the data was copied.","type":"Pipeline","params":[{"type":"text","name":"srcFS","required":true,"value":"@GETSOURCE","parameterType":"com.acxiom.pipeline.fs.FileManager","description":"The source FileManager"},{"type":"text","name":"srcPath","required":true,"value":"!sourceCopyPath","parameterType":"String","description":"Maps the value from the sourceCopyPath global."},{"type":"text","name":"destFS","required":true,"value":"@GETDESTINATION","parameterType":"com.acxiom.pipeline.fs.FileManager","description":"The destination FileManager"},{"type":"text","name":"destPath","required":true,"value":"!destinationCopyPath","parameterType":"String","description":"Maps the value from the destinationCopyPath global."}],"engineMeta":{"spark":"FileManagerSteps.compareFileSizes","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"Int"}},"nextStepId":"TO_STRING","stepId":"1af68ab5-a3fe-4afb-b5fa-34e52f7c77f5","retryLimit":-1},{"id":"TO_STRING","displayName":"To String","description":"Converts the output of the VERIFY step to a string.","type":"Pipeline","params":[{"type":"text","name":"value","required":true,"value":"@VERIFY","parameterType":"Any","description":"The output of the VERIFY step."},{"type":"boolean","name":"unwrapOption","required":false,"value":false,"parameterType":"Boolean","description":"Boolean indicating whether to unwrap the value from an Option prior to calling toString"}],"engineMeta":{"spark":"StringSteps.toString","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"String"}},"nextStepId":"CHECKRESULTS","stepId":"b5485d97-d4e8-41a6-8af7-9ce79a435140","retryLimit":-1},{"id":"CHECKRESULTS","displayName":"String Equals","description":"Return whether string1 equals string2","type":"branch","params":[{"type":"text","name":"string","required":true,"value":"@TO_STRING","parameterType":"String","description":"Maps the output of the TO_STRING step."},{"type":"text","name":"anotherString","required":true,"value":"0","parameterType":"String","description":"Set to 0 indicating no difference."},{"type":"boolean","name":"caseInsensitive","required":false,"value":false,"parameterType":"Boolean","description":"Set to ignore the case of the mapped value."},{"type":"result","name":"true","required":false,"value":"CLOSESOURCE","description":""},{"type":"result","name":"false","required":false,"value":"DELETEDESTINATION","description":""}],"engineMeta":{"spark":"StringSteps.stringEquals","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"Boolean"}},"stepId":"3fabf9ec-5383-4eb3-81af-6092ab7c370d","retryLimit":-1},{"id":"CLOSESOURCE","displayName":"Disconnect a FileManager","description":"Disconnects the  FileManager from the GETSOURCE step.","type":"Pipeline","params":[{"type":"text","name":"fileManager","required":true,"value":"@GETSOURCE","parameterType":"com.acxiom.pipeline.fs.FileManager","description":"The file manager from the GETSOURCE step."}],"engineMeta":{"spark":"FileManagerSteps.disconnectFileManager","pkg":"com.acxiom.pipeline.steps"},"nextStepId":"CLOSEDESTINATION","stepId":"3d1e8519-690c-55f0-bd05-1e7b97fb6633","retryLimit":-1},{"id":"CLOSEDESTINATION","displayName":"Disconnect a FileManager","description":"Disconnects a FileManager from the GETDESTINATION step.","type":"Pipeline","params":[{"type":"text","name":"fileManager","required":true,"value":"@GETDESTINATION","parameterType":"com.acxiom.pipeline.fs.FileManager","description":"The file manager from the GETDESTINATION step."}],"engineMeta":{"spark":"FileManagerSteps.disconnectFileManager","pkg":"com.acxiom.pipeline.steps"},"stepId":"3d1e8519-690c-55f0-bd05-1e7b97fb6633","retryLimit":-1},{"id":"DELETEDESTINATION","displayName":"Delete (file)","description":"Delete a file","type":"Pipeline","params":[{"type":"text","name":"fileManager","required":true,"value":"@GETDESTINATION","parameterType":"com.acxiom.pipeline.fs.FileManager","description":"Uses the FileeManager from thee GETDESTINATION step."},{"type":"text","name":"path","required":true,"value":"!destinationCopyPath","parameterType":"String","description":"Maps the value from the destinationCopyPath global."}],"engineMeta":{"spark":"FileManagerSteps.deleteFile","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"Boolean"}},"nextStepId":"RETRY","stepId":"bf2c4df8-a215-480b-87d8-586984e04189","retryLimit":-1},{"id":"RETRY","displayName":"Retry (simple)","description":"Makes a decision to retry or stop based on a named counter","type":"branch","params":[{"type":"text","name":"counterName","required":true,"value":"COPY_FILE_RETRY","parameterType":"String","description":"Sets the name of the tracking counter to COPY_FILE_RETRY."},{"type":"integer","name":"maxRetries","required":true,"value":5,"parameterType":"Int","description":"The maximum number of retries will be 5."},{"type":"result","name":"retry","required":false,"value":"COPY","description":""},{"type":"result","name":"stop","required":false,"value":"CLOSESOURCE","description":""}],"engineMeta":{"spark":"FlowUtilsSteps.simpleRetry","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"com.acxiom.pipeline.PipelineStepResponse"}},"stepId":"6ed36f89-35d1-4280-a555-fbcd8dd76bf2","retryLimit":-1}],"category":"pipeline","tags":["metalus-common_2.11-spark_2.4-1.9.0.jar"],"description":"Copies a file from the provided source location to thee specified destination. After the copy is complete, the results are verified. If the copy failed, then it will be retried 5 times."}]
