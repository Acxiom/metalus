[{"id":"a8f1acd0-c39b-11eb-b944-4f8822efc9f5","name":"WriteDataFrameToS3","steps":[{"id":"Get_Credential","displayName":"Get Credential","description":"This step provides access to credentials through the CredentialProvider","type":"Pipeline","params":[{"type":"text","name":"credentialName","required":true,"value":"!credentialName","parameterType":"String","description":"The dataset containing CSV strings"}],"engineMeta":{"spark":"CredentialSteps.getCredential","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"com.acxiom.pipeline.Credential"}},"nextStepId":"WriteToParquetS3","stepId":"86c84fa3-ad45-4a49-ac05-92385b8e9572"},{"id":"WriteToParquetS3","displayName":"Write DataFrame to S3","description":"This step will write a DataFrame in a given format to S3","type":"Pipeline","params":[{"type":"text","name":"dataFrame","required":true,"value":"!inputDataFrame","description":"The DataFrame to post to the Kinesis stream"},{"type":"text","name":"path","required":true,"value":"!{bronzeZonePath}/!{fileId}","description":"The S3 path to write data"},{"type":"text","name":"accessKeyId","required":false,"value":"@Get_Credential.awsAccessKey","description":"The optional API key to use for S3 access"},{"type":"text","name":"secretAccessKey","required":false,"value":"@Get_Credential.awsAccessSecret","description":"The optional API secret to use for S3 access"},{"type":"object","name":"options","required":false,"value":{"format":"parquet","bucketingOptions":{},"options":{"escapeQuotes":false},"schema":{"attributes":[]},"saveMode":"Overwrite"},"className":"com.acxiom.pipeline.steps.DataFrameWriterOptions","description":"The optional DataFrame Options"}],"engineMeta":{"spark":"S3Steps.writeToPath","pkg":"com.acxiom.aws.steps"},"stepId":"7dc79901-795f-4610-973c-f46da63f669c"}],"category":"step-group","tags":["metalus-aws_2.11-spark_2.4-1.8.1.jar"]},{"id":"ff30fd80-c39b-11eb-b944-4f8822efc9f5","name":"LoadS3Data","steps":[{"id":"Get_Credentials","displayName":"Get Credential","description":"This step provides access to credentials through the CredentialProvider","type":"Pipeline","params":[{"type":"text","name":"credentialName","required":true,"value":"!credentialName","parameterType":"String","description":"The dataset containing CSV strings"}],"engineMeta":{"spark":"CredentialSteps.getCredential","pkg":"com.acxiom.pipeline.steps","results":{"primaryType":"com.acxiom.pipeline.Credential"}},"nextStepId":"LoadS3Data","stepId":"86c84fa3-ad45-4a49-ac05-92385b8e9572"},{"id":"LoadS3Data","displayName":"Load DataFrame from S3 path","description":"This step will read a DataFrame from the given S3 path","type":"Pipeline","params":[{"type":"text","name":"path","required":true,"value":"!{landingPath}/!{fileId}","description":"The S3 path to load data"},{"type":"text","name":"accessKeyId","required":false,"value":"@Get_Credentials.awsAccessKey","description":"The optional API key to use for S3 access"},{"type":"text","name":"secretAccessKey","required":false,"value":"@Get_Credentials.awsAccessSecret","description":"The optional API secret to use for S3 access"},{"type":"object","name":"options","required":false,"value":"!readOptions","className":"com.acxiom.pipeline.steps.DataFrameReaderOptions","description":"The optional DataFrame Options"}],"engineMeta":{"spark":"S3Steps.readFromPath","pkg":"com.acxiom.aws.steps","results":{"primaryType":"org.apache.spark.sql.DataFrame"}},"stepId":"bd4a944f-39ad-4b9c-8bf7-6d3c1f356510"}],"category":"step-group","tags":["metalus-aws_2.11-spark_2.4-1.8.1.jar"],"stepGroupResult":"@LoadS3Data"}]
