{"pkgs":["com.acxiom.aws.steps"],"steps":[{"id":"207aa871-4f83-4e24-bab3-4e47bb3b667a","displayName":"Write DataFrame to a Kinesis Stream","description":"This step will write a DataFrame to a Kinesis Stream","type":"Pipeline","category":"AWS","params":[{"type":"text","name":"dataFrame","required":true,"parameterType":"org.apache.spark.sql.DataFrame","description":"The DataFrame to post to the Kinesis stream"},{"type":"text","name":"region","required":true,"parameterType":"String","description":"The region of the Kinesis stream"},{"type":"text","name":"streamName","required":true,"parameterType":"String","description":"The name of the Kinesis stream"},{"type":"text","name":"partitionKey","required":true,"parameterType":"String","description":"The key to use when partitioning the message"},{"type":"text","name":"separator","required":false,"parameterType":"String","description":"The separator character to use when combining the column data"},{"type":"text","name":"accessKeyId","required":false,"parameterType":"String","description":"The optional API key to use for the Kinesis stream"},{"type":"text","name":"secretAccessKey","required":false,"parameterType":"String","description":"The optional API secret to use for the Kinesis stream"}],"engineMeta":{"spark":"KinesisSteps.writeToStream","pkg":"com.acxiom.aws.steps"},"tags":["metalus-aws_2.12-spark_3.1-1.8.6-SNAPSHOT.jar"]},{"id":"5c9c7056-5c7a-4463-93c8-7e99bad66d4f","displayName":"Write DataFrame to a Kinesis Stream Using Global Credentials","description":"This step will write a DataFrame to a Kinesis Stream using the CredentialProvider to get Credentials","type":"Pipeline","category":"AWS","params":[{"type":"text","name":"dataFrame","required":true,"parameterType":"org.apache.spark.sql.DataFrame","description":"The DataFrame to post to the Kinesis stream"},{"type":"text","name":"region","required":true,"parameterType":"String","description":"The region of the Kinesis stream"},{"type":"text","name":"streamName","required":true,"parameterType":"String","description":"The name of the Kinesis stream"},{"type":"text","name":"partitionKey","required":true,"parameterType":"String","description":"The key to use when partitioning the message"},{"type":"text","name":"separator","required":false,"parameterType":"String","description":"The separator character to use when combining the column data"}],"engineMeta":{"spark":"KinesisSteps.writeStream","pkg":"com.acxiom.aws.steps"},"tags":["metalus-aws_2.12-spark_3.1-1.8.6-SNAPSHOT.jar"]},{"id":"52f161a5-3025-4e40-a10b-f201940b5cbf","displayName":"Write a single message to a Kinesis Stream Using Global Credentials","description":"This step will write a single message to a Kinesis Stream using the CredentialProvider to get Credentials","type":"Pipeline","category":"AWS","params":[{"type":"text","name":"message","required":true,"parameterType":"String","description":"The message to post to the Kinesis stream"},{"type":"text","name":"region","required":true,"parameterType":"String","description":"The region of the Kinesis stream"},{"type":"text","name":"streamName","required":true,"parameterType":"String","description":"The name of the Kinesis stream"},{"type":"text","name":"partitionKey","required":true,"parameterType":"String","description":"The key to use when partitioning the message"}],"engineMeta":{"spark":"KinesisSteps.postMessage","pkg":"com.acxiom.aws.steps"},"tags":["metalus-aws_2.12-spark_3.1-1.8.6-SNAPSHOT.jar"]},{"id":"3079d815-9105-4194-a8f1-6546531b3373","displayName":"Write a single message to a Kinesis Stream","description":"This step will write a single message to a Kinesis Stream","type":"Pipeline","category":"AWS","params":[{"type":"text","name":"message","required":true,"parameterType":"String","description":"The message to post to the Kinesis stream"},{"type":"text","name":"region","required":true,"parameterType":"String","description":"The region of the Kinesis stream"},{"type":"text","name":"streamName","required":true,"parameterType":"String","description":"The name of the Kinesis stream"},{"type":"text","name":"partitionKey","required":true,"parameterType":"String","description":"The key to use when partitioning the message"},{"type":"text","name":"accessKeyId","required":false,"parameterType":"String","description":"The optional API key to use for the Kinesis stream"},{"type":"text","name":"secretAccessKey","required":false,"parameterType":"String","description":"The optional API secret to use for the Kinesis stream"}],"engineMeta":{"spark":"KinesisSteps.postMessage","pkg":"com.acxiom.aws.steps"},"tags":["metalus-aws_2.12-spark_3.1-1.8.6-SNAPSHOT.jar"]},{"id":"75dca4ff-d4c1-4171-8cea-a303c17d461d","displayName":"Register S3 FS Providers","description":"Registers the S3N and S3A File System providers","type":"Pipeline","category":"AWS","params":[],"engineMeta":{"spark":"S3Steps.registerS3FileSystems","pkg":"com.acxiom.aws.steps"},"tags":["metalus-aws_2.12-spark_3.1-1.8.6-SNAPSHOT.jar"]},{"id":"18290ec4-93e1-427c-8f46-2eb48dd7d1fd","displayName":"Setup S3 Authentication","description":"This step will setup authentication read for DataFrames using the provided key and secret","type":"Pipeline","category":"AWS","params":[{"type":"text","name":"accessKeyId","required":false,"parameterType":"String","description":"The API key to use for S3 access"},{"type":"text","name":"secretAccessKey","required":false,"parameterType":"String","description":"The API secret to use for S3 access"},{"type":"text","name":"accountId","required":false,"parameterType":"String","description":"The account id for the assume role request"},{"type":"text","name":"role","required":false,"parameterType":"String","description":"The role to assume"},{"type":"text","name":"partition","required":false,"defaultValue":"aws","parameterType":"String","description":"The partition name"}],"engineMeta":{"spark":"S3Steps.setupS3Authentication","pkg":"com.acxiom.aws.steps"},"tags":["metalus-aws_2.12-spark_3.1-1.8.6-SNAPSHOT.jar"]},{"id":"bd4a944f-39ad-4b9c-8bf7-6d3c1f356510","displayName":"Load DataFrame from S3 path","description":"This step will read a DataFrame from the given S3 path","type":"Pipeline","category":"AWS","params":[{"type":"text","name":"path","required":true,"parameterType":"String","description":"The S3 path to load data"},{"type":"text","name":"accessKeyId","required":false,"parameterType":"String","description":"The optional API key to use for S3 access"},{"type":"text","name":"secretAccessKey","required":false,"parameterType":"String","description":"The optional API secret to use for S3 access"},{"type":"text","name":"accountId","required":false,"parameterType":"String"},{"type":"text","name":"role","required":false,"parameterType":"String"},{"type":"text","name":"partition","required":false,"parameterType":"String"},{"type":"text","name":"duration","required":false,"parameterType":"String"},{"type":"object","name":"options","required":false,"className":"com.acxiom.pipeline.steps.DataFrameReaderOptions","parameterType":"com.acxiom.pipeline.steps.DataFrameReaderOptions","description":"The optional DataFrame Options"}],"engineMeta":{"spark":"S3Steps.readFromPath","pkg":"com.acxiom.aws.steps","results":{"primaryType":"org.apache.spark.sql.DataFrame"}},"tags":["metalus-aws_2.12-spark_3.1-1.8.6-SNAPSHOT.jar"]},{"id":"8714aa73-fdb5-4e9f-a8d3-5a813fe14a9e","displayName":"Load DataFrame from S3 paths","description":"This step will read a dataFrame from the given S3 paths","type":"Pipeline","category":"AWS","params":[{"type":"text","name":"paths","required":true,"parameterType":"List[String]","description":"The S3 paths to load data"},{"type":"text","name":"accessKeyId","required":false,"parameterType":"String","description":"The optional API key to use for S3 access"},{"type":"text","name":"secretAccessKey","required":false,"parameterType":"String","description":"The optional API secret to use for S3 access"},{"type":"text","name":"accountId","required":false,"parameterType":"String"},{"type":"text","name":"role","required":false,"parameterType":"String"},{"type":"text","name":"partition","required":false,"parameterType":"String"},{"type":"text","name":"duration","required":false,"parameterType":"String"},{"type":"object","name":"options","required":false,"className":"com.acxiom.pipeline.steps.DataFrameReaderOptions","parameterType":"com.acxiom.pipeline.steps.DataFrameReaderOptions","description":"The optional DataFrame Options"}],"engineMeta":{"spark":"S3Steps.readFromPaths","pkg":"com.acxiom.aws.steps","results":{"primaryType":"org.apache.spark.sql.DataFrame"}},"tags":["metalus-aws_2.12-spark_3.1-1.8.6-SNAPSHOT.jar"]},{"id":"7dc79901-795f-4610-973c-f46da63f669c","displayName":"Write DataFrame to S3","description":"This step will write a DataFrame in a given format to S3","type":"Pipeline","category":"AWS","params":[{"type":"text","name":"dataFrame","required":true,"parameterType":"org.apache.spark.sql.DataFrame","description":"The DataFrame to post to the Kinesis stream"},{"type":"text","name":"path","required":true,"parameterType":"String","description":"The S3 path to write data"},{"type":"text","name":"accessKeyId","required":false,"parameterType":"String","description":"The optional API key to use for S3 access"},{"type":"text","name":"secretAccessKey","required":false,"parameterType":"String","description":"The optional API secret to use for S3 access"},{"type":"text","name":"accountId","required":false,"parameterType":"String"},{"type":"text","name":"role","required":false,"parameterType":"String"},{"type":"text","name":"partition","required":false,"parameterType":"String"},{"type":"text","name":"duration","required":false,"parameterType":"String"},{"type":"object","name":"options","required":false,"className":"com.acxiom.pipeline.steps.DataFrameWriterOptions","parameterType":"com.acxiom.pipeline.steps.DataFrameWriterOptions","description":"The optional DataFrame Options"}],"engineMeta":{"spark":"S3Steps.writeToPath","pkg":"com.acxiom.aws.steps"},"tags":["metalus-aws_2.12-spark_3.1-1.8.6-SNAPSHOT.jar"]},{"id":"cc4694b9-5e54-4b12-8088-ed4ced056efd","displayName":"Create S3 FileManager","description":"Simple function to generate the S3FileManager for a S3 file system","type":"Pipeline","category":"AWS","params":[{"type":"text","name":"region","required":true,"parameterType":"String","description":"The region of the S3 bucket"},{"type":"text","name":"bucket","required":true,"parameterType":"String","description":"The S3 bucket"},{"type":"text","name":"accessKeyId","required":false,"parameterType":"String","description":"The optional API key to use for S3 access"},{"type":"text","name":"secretAccessKey","required":false,"parameterType":"String","description":"The optional API secret to use for S3 access"},{"type":"text","name":"accountId","required":false,"parameterType":"String"},{"type":"text","name":"role","required":false,"parameterType":"String"},{"type":"text","name":"partition","required":false,"parameterType":"String"}],"engineMeta":{"spark":"S3Steps.createFileManager","pkg":"com.acxiom.aws.steps","results":{"primaryType":"com.acxiom.aws.fs.S3FileManager"}},"tags":["metalus-aws_2.12-spark_3.1-1.8.6-SNAPSHOT.jar"]},{"id":"0e3bcadd-2d14-408f-982f-32ffd879d795d","displayName":"Create S3 FileManager with Client","description":"Simple function to generate the S3FileManager for a S3 file system using an existing client","type":"Pipeline","category":"AWS","params":[{"type":"text","name":"s3Client","required":true,"parameterType":"com.amazonaws.services.s3.AmazonS3","description":"An existing S3 client use to access the bucket"},{"type":"text","name":"bucket","required":true,"parameterType":"String","description":"The S3 bucket"}],"engineMeta":{"spark":"S3Steps.createFileManagerWithClient","pkg":"com.acxiom.aws.steps","results":{"primaryType":"com.acxiom.aws.fs.S3FileManager"}},"tags":["metalus-aws_2.12-spark_3.1-1.8.6-SNAPSHOT.jar"]}],"pkgObjs":[{"id":"com.acxiom.pipeline.steps.DataFrameReaderOptions","schema":"{\"$schema\":\"http://json-schema.org/draft-07/schema#\",\"title\":\"Data Frame Reader Options\",\"type\":\"object\",\"additionalProperties\":false,\"properties\":{\"format\":{\"type\":\"string\"},\"options\":{\"type\":\"object\",\"additionalProperties\":{\"type\":\"string\"}},\"schema\":{\"$ref\":\"#/definitions/Schema\"}},\"definitions\":{\"Schema\":{\"type\":\"object\",\"additionalProperties\":false,\"properties\":{\"attributes\":{\"type\":\"array\",\"items\":{\"$ref\":\"#/definitions/Attribute\"}}}},\"Attribute\":{\"type\":\"object\",\"additionalProperties\":false,\"properties\":{\"name\":{\"type\":\"string\"},\"dataType\":{\"$ref\":\"#/definitions/AttributeType\"},\"nullable\":{},\"metadata\":{\"type\":\"object\",\"additionalProperties\":{}}}},\"AttributeType\":{\"type\":\"object\",\"additionalProperties\":false,\"properties\":{\"baseType\":{\"type\":\"string\"},\"valueType\":{\"$ref\":\"#/definitions/AttributeType\"},\"nameType\":{\"$ref\":\"#/definitions/AttributeType\"},\"schema\":{\"$ref\":\"#/definitions/Schema\"}}}}}"},{"id":"com.acxiom.pipeline.steps.DataFrameWriterOptions","schema":"{\"$schema\":\"http://json-schema.org/draft-07/schema#\",\"title\":\"Data Frame Writer Options\",\"type\":\"object\",\"additionalProperties\":false,\"properties\":{\"format\":{\"type\":\"string\"},\"saveMode\":{\"type\":\"string\"},\"options\":{\"type\":\"object\",\"additionalProperties\":{\"type\":\"string\"}},\"bucketingOptions\":{\"$ref\":\"#/definitions/BucketingOptions\"},\"partitionBy\":{\"type\":\"array\",\"items\":{\"type\":\"string\"}},\"sortBy\":{\"type\":\"array\",\"items\":{\"type\":\"string\"}}},\"definitions\":{\"BucketingOptions\":{\"type\":\"object\",\"additionalProperties\":false,\"properties\":{\"numBuckets\":{\"type\":\"integer\"},\"columns\":{\"type\":\"array\",\"items\":{\"type\":\"string\"}}},\"required\":[\"numBuckets\"]}}}"}]}
